{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = b = c= list(range(20))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 2),\n",
       " (3, 3),\n",
       " (4, 4),\n",
       " (5, 5),\n",
       " (6, 6),\n",
       " (7, 7),\n",
       " (8, 8),\n",
       " (9, 9),\n",
       " (10, 10),\n",
       " (11, 11),\n",
       " (12, 12),\n",
       " (13, 13),\n",
       " (14, 14),\n",
       " (15, 15),\n",
       " (16, 16),\n",
       " (17, 17),\n",
       " (18, 18),\n",
       " (19, 19)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(a,b,c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      " \n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      " \n",
      "g\n",
      "o\n",
      "o\n",
      "d\n",
      " \n",
      "b\n",
      "y\n",
      "e\n",
      "0:00:00.001386\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "x = [\"hello world \", \"good bye\"]\n",
    "for i in x:\n",
    "    for j in i:\n",
    "        print(j)\n",
    "finish = datetime.datetime.now()\n",
    "print(finish-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda arguments: expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add5 = lambda x: x + 5\n",
    "add5(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square = lambda x: x * x\n",
    "square(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "get_tens_remainder = lambda x: int(x/10)%10\n",
    "print(get_tens_remainder(749))\n",
    "print(get_tens_remainder(836.21))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('carrots', 1.1), ('eggs', 5.25), ('honey', 9.7), 'peaches, 2.45']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = [('eggs', 5.25), ('honey', 9.70), ('carrots', 1.10), ('peaches, 2.45')] #list of tuples\n",
    "list1.sort(key = lambda x: x[0]) #using key function, sorts by key (0 for key, 1 for value)\n",
    "list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'year': 1999}, {'year': 2008}, {'year': 2013}]\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "list1 = [{\"year\":2013}, {'year':1999}, {'year':2008}]\n",
    "list2 = sorted(list1, key = lambda x: x['year'])  #sorted returns a new sorted list, leaves original list unaffected\n",
    "pp.pprint(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6]\n",
      "[2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "list1 = list(range(1,7)) #start at index 1, end at index 6\n",
    "print(list1)\n",
    "list2 = list(filter(lambda x: x%2 ==0, list1)) #filters items in the list\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "odds = lambda x: x%2 == 1\n",
    "list1 = list(range(1,7))\n",
    "list2 = list(filter(odds, list1))\n",
    "print(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map(function, iterable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25, 36]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = list(range(1,7))\n",
    "list2 = list(map(lambda x: x ** 2, list1))\n",
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Conditionals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda arguments: a if boolean_expression else b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "starts_with_J = lambda x: True if x.startswith('J') else False #startswith method\n",
    "print(starts_with_J('Joey'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splits string into a list, and index the word minus 1\n",
    "wordb4 = lambda s, w: s.split()[s.split().index(w)-1] if w in s else None \n",
    "sentence = \"Four score and seven years ago\"\n",
    "wordb4(sentence, \"seven\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda on DateTime Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "year = lambda x: x.year #converts to year only\n",
    "year(now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda within a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda function can be a 1st level object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "125\n"
     ]
    }
   ],
   "source": [
    "def do_something(f, val):\n",
    "    return f(val)\n",
    "\n",
    "func = lambda x: x**3 #cube\n",
    "print(func(16)) \n",
    "print(do_something(func,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "-1\n",
      "-21.67 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#test if a string is a number\n",
    "isnum = lambda x: x.replace('.','',1).isdigit() #if ., replace with blank, once\n",
    "print(isnum('25983'))\n",
    "print(isnum('3.1415'))\n",
    "print(isnum('T57'))\n",
    "print(isnum('-16'))\n",
    "\n",
    "#test if a string with negative sign (level 2 lambda function)\n",
    "#if string start with negative sign, then return index 1 and onwards, else return string as is\n",
    "is_num = lambda y: isnum(y[1:]) if y[0]=='-' else isnum(y)\n",
    "print(is_num('-16'))\n",
    "\n",
    "#convert to number (level 3 lambda function)\n",
    "#if string is a number (positive and negtive), convert to float, else return -1 \n",
    "tonum = lambda z: float(z) if is_num(z) else -1\n",
    "print(tonum('30y'))\n",
    "print(tonum('-21.67'), type(tonum('-21.67'))) #checks type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Map (Series Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maps an existing series to a different set of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sex_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Sex_num\n",
       "0    male        1\n",
       "1  female        0\n",
       "2  female        0\n",
       "3  female        0\n",
       "4    male        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maps Sex series to different column\n",
    "train['Sex_num'] = train.Sex.map({'female':0, 'male':1}) #map to a dictionary where female is 0, and male is 1\n",
    "train.loc[0:4, ['Sex', 'Sex_num']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Apply (Series and Dataframe method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a function to each element in a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Name_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  Name_length\n",
       "0                            Braund, Mr. Owen Harris           23\n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...           51\n",
       "2                             Heikkinen, Miss. Laina           22\n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)           44\n",
       "4                           Allen, Mr. William Henry           24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate length of name string in the name column\n",
    "train['Name_length'] = train.Name.apply(len)\n",
    "train.loc[0:4, ['Name', 'Name_length']]  #index row, then column based on value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Fare_ceil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Fare_ceil\n",
       "0   7.2500        8.0\n",
       "1  71.2833       72.0\n",
       "2   7.9250        8.0\n",
       "3  53.1000       54.0\n",
       "4   8.0500        9.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate ceiling using numpy function\n",
    "import numpy as np\n",
    "train['Fare_ceil'] = train.Fare.apply(np.ceil)\n",
    "train.loc[0:4, ['Fare','Fare_ceil']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a function to each element in a series with LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Braund\n",
      "1      Cumings\n",
      "2    Heikkinen\n",
      "3     Futrelle\n",
      "4        Allen\n",
      "Name: Name, dtype: object\n",
      "0       Braund\n",
      "1      Cumings\n",
      "2    Heikkinen\n",
      "3     Futrelle\n",
      "4        Allen\n",
      "Name: Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#split string into list\n",
    "train.Name.str.split(',').head()\n",
    "\n",
    "#create fuction to get 0th index of the string list\n",
    "def get_element(my_list, position):\n",
    "    return my_list[position]\n",
    "\n",
    "#use apply to get last name of each person\n",
    "x = train.Name.str.split(',').apply(get_element, position=0).head()\n",
    "print(x)\n",
    "\n",
    "#completed in lambda\n",
    "x = train.Name.str.split(',').apply(lambda x: x[0]).head()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a function to each element in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "beer_servings      376\n",
       "spirit_servings    438\n",
       "wine_servings      370\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "print(drinks.head())\n",
    "#apply max value of the selected columns\n",
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(max, axis=0) #axis=0 is column direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/pyfull36/lib/python3.6/site-packages/numpy/core/fromnumeric.py:61: FutureWarning: 'argmax' is deprecated. Use 'idxmax' instead. The behavior of 'argmax' will be corrected to return the positional maximum in the future. Use 'series.values.argmax' to get the position of the maximum now.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      beer_servings\n",
       "1    spirit_servings\n",
       "2      beer_servings\n",
       "3      wine_servings\n",
       "4      beer_servings\n",
       "dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.argmax is the max value in a specific column \n",
    "drinks.loc[:, 'beer_servings':'wine_servings'].apply(np.argmax, axis=1).head() #axis=1 is column direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a function to each element in a dataframe with LAMBDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: continent, dtype: bool"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drinks['continent'].apply(lambda x: True if x==\"Asia\" else False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Applymap (Dataframe method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a function to <u>every</u> element of a dataframe, no axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>beer_servings</th>\n",
       "      <th>spirit_servings</th>\n",
       "      <th>wine_servings</th>\n",
       "      <th>total_litres_of_pure_alcohol</th>\n",
       "      <th>continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>89.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>245.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>217.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  beer_servings  spirit_servings  wine_servings  \\\n",
       "0  Afghanistan            0.0              0.0            0.0   \n",
       "1      Albania           89.0            132.0           54.0   \n",
       "2      Algeria           25.0              0.0           14.0   \n",
       "3      Andorra          245.0            138.0          312.0   \n",
       "4       Angola          217.0             57.0           45.0   \n",
       "\n",
       "   total_litres_of_pure_alcohol continent  \n",
       "0                           0.0      Asia  \n",
       "1                           4.9    Europe  \n",
       "2                           0.7    Africa  \n",
       "3                          12.4    Europe  \n",
       "4                           5.9    Africa  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drinks.loc[:, 'beer_servings':'wine_servings'] = drinks.loc[:, 'beer_servings':'wine_servings'].applymap(float)\n",
    "drinks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".split() - str.split(',') - split strings into a list <br>\n",
    ".replace() - .replace('.','',1) - replace . with '' once <br>\n",
    ".join() - ''.join() - join strings together <br>\n",
    ".reverse() - reverse strings <br>\n",
    ".count(o) - counts o in string <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorize - Assign new ID based on unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    historical['Customer_ID'] = pd.factorize(historical['MatchKey'])[0] + 1000\n",
    "    \n",
    "pd.factorize returns tuple of arrays where `[0]` is codes and `[1]` is unique values. We need codes so we index `[0]`. pd.factorize is a built-in vectorized method which is much faster than using apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask - Slice date based on values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert date format\n",
    "data['POL_CHGEFF_DATE']=pd.to_datetime(data['POL_CHGEFF_DATE'])\n",
    "\n",
    "#filter to weekly data for testing\n",
    "start_date = '2019-08-01'\n",
    "end_date = '2019-08-07'\n",
    "mask = (data['POL_CHGEFF_DATE'] >= start_date) & (data['POL_CHGEFF_DATE'] <= end_date)\n",
    "data = data[mask]\n",
    "\n",
    "#Test using daily refresh\n",
    "data = data[(data['POL_CHGEFF_DATE'] == '2019-08-01')]\n",
    "print(\"Number of test records: \" + str(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice certain columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "historical.iloc[:, np.r_[0:5, 6:len(historical.columns)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice Certain columns with filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = df.columns.get_loc('FIRST_NAME')\n",
    "b = df.columns.get_loc('LAST_NAME')\n",
    "c = df.columns.get_loc('POLICY_NUMBER')\n",
    "d = df.columns.get_loc('STATUS_CODE')\n",
    "e = df.columns.get_loc('LINE_OF_BUSINESS_CODE')\n",
    "f = df.columns.get_loc('Customer_ID')\n",
    "\n",
    "df = df.iloc[:, np.r_[a:a+1, b:b+1, c:c+1, d:d+1, e:e+1, f:f+1]]\n",
    "df = df[(df['STATUS_CODE'] == 'AC')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice using loc and iloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_pol = refresh.iloc[i,refresh.columns.get_loc('Pol_set')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice every nth row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every odd row\n",
    "df.iloc[::2, :].sort_values(by='Customer_ID')\n",
    "\n",
    "# Every even row\n",
    "df.iloc[::-2, :].sort_values(by='Customer_ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Set from Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "historical = pd.DataFrame({'Last_Name': ['Alice', 'Bob'],\n",
    "                   'Gender': ['F', 'M'],\n",
    "                   'Date_of_Birth': ['1990-01-01', '1986-02-02'],\n",
    "                   'Account_Number': [123, 456],\n",
    "                   'Customer_ID': [1001,1002],\n",
    "                   'Status': [\"Active\",\"Inactive\"],\n",
    "                   'Pol_set':[{151,454},{787,878}]\n",
    "                          })\n",
    "refresh = pd.DataFrame({'Last_Name': [\"John\", 'Alice'],\n",
    "                   'Gender': ['M','F'],\n",
    "                   'Date_of_Birth': ['1990-01-01', '1990-01-01'],\n",
    "                   'Account_Number': [567,123],\n",
    "                   'Status': [\"Inactive\",\"Active\"],\n",
    "                   'Pol_set': [{858},{171}]})\n",
    "\n",
    "historical['Pol_set'][0] = historical['Pol_set'].values[0] - (refresh['Pol_set'].values[1])\n",
    "historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Set from Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "historical = pd.DataFrame({'Last_Name': ['Alice', 'Bob'],\n",
    "                   'Gender': ['F', 'M'],\n",
    "                   'Date_of_Birth': ['1990-01-01', '1986-02-02'],\n",
    "                   'Account_Number': [123, 456],\n",
    "                   'Customer_ID': [1001,1002],\n",
    "                   'Status': [\"Active\",\"Inactive\"],\n",
    "                   'Pol_set':[{151,454},{787,878}]\n",
    "                          })\n",
    "refresh = pd.DataFrame({'Last_Name': [\"John\", 'Alice'],\n",
    "                   'Gender': ['M','F'],\n",
    "                   'Date_of_Birth': ['1990-01-01', '1990-01-01'],\n",
    "                   'Account_Number': [567,123],\n",
    "                   'Status': [\"Inactive\",\"Active\"],\n",
    "                   'Pol_set': [{858},{171}]})\n",
    "\n",
    "historical['Pol_set'][0] = historical['Pol_set'].values[0].union(refresh['Pol_set'].values[1])\n",
    "historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Return boolean without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .any() to return any element with True (otherwise False)\n",
    "historical.loc[j, \"Customer_ID\"].isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas index value without dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = pd.DataFrame({'Last_Name': ['Alice', 'Bob'],\n",
    "                   'Gender': ['F', 'M'],\n",
    "                   'Date_of_Birth': ['1990-01-01', '1986-02-02'],\n",
    "                   'Account_Number': [123, 456],\n",
    "                   'Customer_ID': [1001,1002],\n",
    "                   'Status': [\"Active\",\"Inactive\"],\n",
    "                   'Pol_set':[{151,454},{787,878}]\n",
    "                          })\n",
    "\n",
    "historical['Pol_set'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert loc to iloc when indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = pd.DataFrame({'Last_Name': ['Alice', 'Bob'],\n",
    "                   'Gender': ['F', 'M'],\n",
    "                   'Date_of_Birth': ['1990-01-01', '1986-02-02'],\n",
    "                   'Account_Number': [123, 456],\n",
    "                   'Customer_ID': [1001,1002],\n",
    "                   'Status': [\"Active\",\"Inactive\"],\n",
    "                   'Pol_set':[{151,454},{787,878}]\n",
    "                           \n",
    "historical.loc[historical[\"MatchKey\"] == refreshMatchKey,'Pol_set'].index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of Values Count for items greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Test'].value_counts.ne(1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Length of non-exclusive data in two dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use isin with negation and then sum\n",
    "(~df2['ID'].isin(df1['ID'])).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rows for non-exclusive data in two dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[~df1['CUXID'].apply(tuple,1).isin(df2['CUXID'].apply(tuple,1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert date using lambda and filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert date formart\n",
    "import datetime as dt\n",
    "data['POL_CHGEFF_DATE'] = data['POL_CHGEFF_DATE'].apply(lambda x: dt.datetime.strptime(x,'%d%b%Y'))\n",
    "\n",
    "#filter to weekly data for testing\n",
    "start_date = '2019-08-01'\n",
    "end_date = '2019-08-07'\n",
    "mask = (data['POL_CHGEFF_DATE'] >= start_date) & (data['POL_CHGEFF_DATE'] <= end_date)\n",
    "data = data[mask]\n",
    "\n",
    "#number of records\n",
    "print(\"Number of test records: \" + str(len(data)))\n",
    "\n",
    "#Test using daily refresh\n",
    "data = data[(data['POL_CHGEFF_DATE'] == '2019-08-01')]\n",
    "print(\"Number of test records: \" + str(len(data)))\n",
    "\n",
    "#reset index\n",
    "data = data.reset_index(drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop_duplicates(subset=['FIRST_NAME', 'LAST_NAME', 'BIRTH_DATE','NEW_ADDR1_1',\n",
    "                                  'NEW_CITY1_1', 'PROV1_1', 'NEW_PC1_1'], keep='first').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concate multiple column into a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['CUXID'] = new_df['custid'].astype(str)+ new_df['bucketid'].astype(str) + new_df['PROV1_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rearrange columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols = cols[17:18] + cols[0:17] + cols[18:]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index in the bracket\n",
    "x = x.drop([0,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate different dataframes without index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of your dataframes\n",
    "pdList = [df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13, df14, df15, df16, df17, df18, df19]\n",
    "new_df = pd.concat(pdList, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate different dataframes by Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3], axis=1) #axis = 1 for columns, 0 for rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert string to set when loading csv in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe will not show the quotes\n",
    "x['pol_set'] = x['pol_set'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ast.literal_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def setConvert(string):\n",
    "    return set() if txt == 'set()' else ast.literal_eval(string)\n",
    "df['pol_set'] = df['pol_set'].apply(setConvert)\n",
    "\n",
    "# Without 'set()' string\n",
    "df['pol_set'] = df['pol_set'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ast.literal_eval() + apply.lambda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "x['pol_set'] = x['pol_set'].apply(lambda x: set() if x == 'set()' else ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limit string length of pandas column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical['Customer_Matchkey'] = historical['Customer_Matchkey'].str.slice(-15,-1)\n",
    "historical['Address_Matchkey'] = historical['Address_Matchkey'].str.slice(-15,-1)\n",
    "historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['pol_set']]\n",
    "df = df.iloc[[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search row 1 from refresh in historical\n",
    "refresh['matchkey'].isin(historical['matchkey'])[0] \n",
    "\n",
    "# Faster searching using set().values\n",
    "refresh['matchkey'].isin(set(historical['matchkey'].values))[0]\n",
    "\n",
    "# Search refresh matchkey row 1 to historical matchkey row\n",
    "i = historical['matchkey'] == refresh['matchkey'][0]\n",
    "# Find index of searched row above\n",
    "j = historical.loc[i].index.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Index as a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop['index_col'] = df_drop.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0:11:06'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "str(datetime.timedelta(seconds=666))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "start1 = timeit.default_timer()\n",
    "print(\"\\n\\nPython script completed, total processing time:\", str(datetime.timedelta(seconds=(stop1-start1))))\n",
    "stop1 = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Date Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POL_CHGEFF_DATE'] = data['POL_CHGEFF_DATE'].apply(lambda x: dt.datetime.strptime(x,'%d%b%Y'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Date Measurement (Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['POL_CHGEFF_DATE']=pd.to_datetime(data['POL_CHGEFF_DATE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtracting Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Difference'] = (df_test['First_Date'] - df_test['Second_Date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter date by 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter date by 1 year\n",
    "date1 = df_trans['POL_CHGEFF_DATE'].max()\n",
    "date2 = df_trans['POL_CHGEFF_DATE'].max() - pd.DateOffset(years=1)\n",
    "df_trans_1year = df_trans[(df_trans['POL_CHGEFF_DATE'] <= date1) & (df_trans['POL_CHGEFF_DATE'] >= date2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today's Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date = pd.Timestamp.now().normalize() # The current date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous Date (Subtracting dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract by 1 year\n",
    "previous_date = end_date - pd.DateOffset(years=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current date\n",
    "end_date = pd.Timestamp.now().normalize()\n",
    "\n",
    "def calculate_age(born):                 \n",
    "    return end_date.year - born.year - ((end_date.month, end_date.day) < (born.month, born.day)) \n",
    "\n",
    "data['BIRTH_DATE'] = pd.to_datetime(data['BIRTH_DATE'], errors='coerce') \n",
    "data['Age'] = data['BIRTH_DATE'].apply(calculate_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Age for Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current date\n",
    "end_date = pd.Timestamp.now().normalize() \n",
    "\n",
    "# Add minimum age of 18 years column\n",
    "data['minimum_age_18'] = end_date - pd.DateOffset(years=18)\n",
    "data['minimum_age_18'] = pd.to_datetime(data['minimum_age_18'], errors='coerce')\n",
    "minimum_age_18 = data['minimum_age_18'][0]\n",
    "\n",
    "# Add maximum age of 100 years column\n",
    "data['maximum_age_100'] = end_date - pd.DateOffset(years=100)\n",
    "data['maximum_age_100'] = pd.to_datetime(data['maximum_age_100'], errors='coerce')\n",
    "maximum_age_100 = data['maximum_age_100'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Age Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter age between 18 to 100\n",
    "df_master_age = df_master[(df_master[\"Age\"] < 100) & (df_master['Age'] >= 18)]\n",
    "\n",
    "# Define age group\n",
    "def ageGroup(age):\n",
    "    if (age >= 18) & (age <= 19):\n",
    "        return \"18 to 19 years\"\n",
    "    elif (age >= 20) & (age <= 29):\n",
    "        return \"20 to 29 years\"\n",
    "    elif (age >= 30) & (age <= 39):\n",
    "        return \"30 to 39 years\"\n",
    "    elif (age >= 40) & (age <= 49):\n",
    "        return \"40 to 49 years\"\n",
    "    elif (age >= 50) & (age <= 59):\n",
    "        return \"50 to 59 years\"\n",
    "    elif (age >= 60) & (age <= 69):\n",
    "        return \"60 to 69 years\"\n",
    "    elif (age >= 70):\n",
    "        return \"70 years and over\"\n",
    "\n",
    "# Apply age group\n",
    "df_master_age['Age_Group'] = df_master_age['Age'].apply(ageGroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read SAS directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "csv = 'auto_prop_cam_202001.sas7bdat'\n",
    "data = pd.read_sas(csv, format = 'sas7bdat',encoding='latin-1')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort Columns Alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refresh = refresh.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Items in a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Customer_ID'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter two items in a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2019-08-01'\n",
    "end_date = '2019-08-07'\n",
    "df = data[(data['POL_CHGEFF_DATE'] >= start_date) & (data['POL_CHGEFF_DATE'] <= end_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter multiple items in a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renew_list = ['RE', 'AC']\n",
    "df_filtered = data[data['STATUS_CODE'].isin(renew_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter two items in a Column with OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['STATUS_CODE'] == 'RE') | (data['STATUS_CODE'] == 'AC')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Missing Value (NaN) in Pandas Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Customer_ID'].isnull() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total missing values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['DRIVEWISE_DISCOUNT_FLAG'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get index number for Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns.get_loc('MAKE_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add New Row in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -1 for last row\n",
    "df.iloc[-1] = ['test',0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge - Convert IDs from one table to another table using Matchkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({'unique_value': ['xyz123', 'eff987', 'efg125', 'xyz123', 'eff987', 'test'], 'ID': [1000, 1001, 1002, 1000, 1001,500]})\n",
    "df2 = pd.DataFrame({'unique_value': ['xyz123', 'xyz123', 'eff987', 'efg125', 'xyz123']})\n",
    "\n",
    "df2 = df2.merge(df1.drop_duplicates(), on='unique_value', how='left')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge - Left Join Without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.merge(df1.drop_duplicates(), on='unique_value', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on='Customer_ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_csv('test2.csv', encoding='latin-1')\n",
    "#del df['Unnamed: 0']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['POLICY_NUMBER']==151809458)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload file without index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical = pd.read_csv(historical_csv, index_col=0, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Certain Rows in a csv File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rows_to_keep = np.arange(0,200,1).tolist()\n",
    "refresh = pd.read_csv('combined_fview_new_phone_20210215.csv', encoding='latin-1', skiprows = lambda x: x not in rows_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a list of numbers using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.arange(0.05, 1.05, 0.05).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round by 2 (.tolist() goes outside)\n",
    "import numpy as np\n",
    "np.round(np.arange(0.05, 1.05, 0.05), 2).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progres update\n",
    "progress = np.round(np.arange(0.05, 1.05, 0.05), 2).tolist() # [0.05, ... , 1.0]\n",
    "for prog in progress:\n",
    "    if i == (len(refresh) * prog):\n",
    "        print(\"Progress update: \" + str(prog * 100) + \"% at \" + str(i) + ' record of out ' + str(len(refresh)) + \" records completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show nicer dataframe using print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(df_term, headers='keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Particle Row and Column in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at for column\n",
    "df['x'].at['C'] = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Two Separate DataFrame with same columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_renew_rate = df_renew.merge(df_total.drop_duplicates(), on='PROV1_1', how='left')\n",
    "df_renew_rate['Customer_ID (%)'] = round(df_renew_rate['Customer_ID_x']/df_renew_rate['Customer_ID_y'], 2)*100\n",
    "df_renew_rate = df_renew_rate.iloc[:,np.r_[0:1,3:4]]\n",
    "print(tabulate(df_renew_rate, headers='keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename Pandas Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"PolicyNumber\": \"POLICY_NUMBER\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Counts for each bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "data[\"BUCKET_ID\"].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum function based on multiple group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(dataset, function, firstGroup, secondGroup, aggregateValue):\n",
    "    if function == 'sum':\n",
    "        dataset['Sum'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.sum())\n",
    "    elif function == 'cum_sum':\n",
    "        dataset['Cum_Sum'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.cumsum())\n",
    "    elif function == 'max':\n",
    "        dataset['Cum_Max'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.cummax())\n",
    "    elif function == 'min':\n",
    "        dataset['Cum_Min'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.cummin())\n",
    "    elif function == 'avg':\n",
    "        dataset['Cum_Mean'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.expanding().sum())\n",
    "    else:\n",
    "        x = input(\"please enter a proper function. Functions include: sum, cum_sum, max, min or avg.\")\n",
    "        print(x)\n",
    "        if x == 'sum':\n",
    "            dataset['Sum'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.sum())\n",
    "        elif x == 'cum_sum':\n",
    "            dataset['Cum_Sum'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.cumsum())\n",
    "        elif x == 'max':\n",
    "            dataset['Cum_Max'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.cummax())\n",
    "        elif x == 'min':\n",
    "            dataset['Cum_Min'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.cummin())\n",
    "        elif x == 'avg':\n",
    "            dataset['Cum_Mean'] = dataset.groupby([firstGroup, secondGroup])[aggregateValue].apply(lambda x: x.expanding().sum())\n",
    "        \n",
    "df_final = add_cum_sum(df, 'sum', \"CustomerID\", 'Pro', \"Policy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivot Table for Unique Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.pivot_table(data, index=['MAKE_NAME', 'MODEL_NAME'], columns=['PROV1_1'], values=['Customer_ID'], aggfunc=lambda x: len(x.unique()))\n",
    "x.dropna()#.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Numbers with Commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 10000000\n",
    "print(f\"{num:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes it to NaT instead of NaN\n",
    "df.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregates operations #frozenset returns immutable objects\n",
    ".agg(frozenset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total number of customer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take total first\n",
    "df_total_cus = data['Customer_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total number of customer ID per province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take total first then group by province\n",
    "df_total = data.groupby(['PROV1_1'])['Customer_ID'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number of Policies each customer has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take total first then group by customers\n",
    "df_avg = data.groupby(['Customer_ID'])['POLICY_NUMBER'].nunique().reset_index() \n",
    "# Then take average\n",
    "df_avg = df_avg['POLICY_NUMBER'].mean().reset_index().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Number of Policies each customer has per province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take total first then group by customers and province\n",
    "df_avg = data.groupby(['Customer_ID', 'PROV1_1'])['POLICY_NUMBER'].nunique().reset_index() \n",
    "# Then take average then group by province\n",
    "df_avg = df_avg.groupby(['PROV1_1'])['POLICY_NUMBER'].mean().reset_index().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total customers with multiple products (Product in different rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st approach\n",
    "df_auto = data[data['LINE_OF_BUSINESS_CODE'] == 'AU']\n",
    "df_prop = data[data['LINE_OF_BUSINESS_CODE'] == 'PR']\n",
    "df_auto = (df_auto[df_auto['Customer_ID'].isin(df_prop['Customer_ID'])])\n",
    "df_auto = df_auto['Customer_ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd approach\n",
    "# Take total first then group by customers\n",
    "out = a.groupby(['Customer_ID'])['LINE_OF_BUSINESS_CODE'].agg(frozenset).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd approach\n",
    "v = ['AU','PR']\n",
    "out = a.groupby('Customer_ID')['LINE_OF_BUSINESS_CODE'].apply(lambda x: set(x) == set(v)).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total customers with multiple products per province (Product in different rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st approach\n",
    "df_auto = data[data['LINE_OF_BUSINESS_CODE'] == 'AU']\n",
    "df_prop = data[data['LINE_OF_BUSINESS_CODE'] == 'PR']\n",
    "df_multi = (df_auto[df_auto['Customer_ID'].isin(df_prop['Customer_ID'])])\n",
    "df_multi = df_multi.groupby('PROV1_1')['Customer_ID'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd approach\n",
    "\n",
    "# Take total first then group by customers\n",
    "out = a.groupby(['Customer_ID', 'PROV1_1'])['LINE_OF_BUSINESS_CODE'].agg(frozenset).reset_index() \n",
    "# Then take toal then group by province\n",
    "out = out.groupby(['PROV1_1'])['LINE_OF_BUSINESS_CODE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Age per Address ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = data.groupby(['Address_ID'])['Age'].mean().reset_index()\n",
    "df_age = df_age['Age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Age per Address ID per province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df_age.groupby(['Address_ID', 'PROV1_1'])['Age'].mean().reset_index()\n",
    "df_age = df_age.groupby(['PROV1_1'])['Age'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total number of vehicles (brand and model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st approach\n",
    "df_total_veh = data.groupby(['MAKE_NAME'])['MODEL_NAME'].nunique().reset_index()\n",
    "df_total_veh = df_total_veh['MODEL_NAME'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd approach\n",
    "#Customer_ID is a throwaway column, .count() will count the MODEL_NAME\n",
    "data.groupby(['MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total number of customers for each vehicle per province (brand and model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_veh = data.groupby(['PROV1_1', 'MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].nunique().reset_index()\n",
    "print(tabulate(df_total_veh, headers='keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 Most Popular Vehicles (brand and model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_veh_top_3 = data.groupby(['MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].nunique().reset_index()\\\n",
    ".sort_values(by='Customer_ID', ascending=False)[0:3]\n",
    "df_veh_top_3 = df_veh_top_3.rename(columns={\"Customer_ID\": \"Customer_ID (Count)\"})\n",
    "print(\"\\n\\n\\n2) Top 3 most popular vehicles:\\n\")\n",
    "print(tabulate(df_veh_top_3, headers='keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3 Most Popular Vehicles per province (brand and model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_3_ON = data[(data['PROV1_1'] == 'ON')]\n",
    "df_top_3_AB = data[(data['PROV1_1'] == 'AB')]\n",
    "df_top_3_NS = data[(data['PROV1_1'] == 'NS')]\n",
    "df_top_3_PQ = data[(data['PROV1_1'] == 'PQ')]\n",
    "df_top_3_ON = df_top_3_ON.groupby(['PROV1_1', 'MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].nunique().reset_index()\\\n",
    ".sort_values(by='Customer_ID', ascending=False)[0:3]\n",
    "df_top_3_AB = df_top_3_AB.groupby(['PROV1_1', 'MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].nunique().reset_index()\\\n",
    ".sort_values(by='Customer_ID', ascending=False)[0:3]\n",
    "df_top_3_NS = df_top_3_NS.groupby(['PROV1_1', 'MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].nunique().reset_index()\\\n",
    ".sort_values(by='Customer_ID', ascending=False)[0:3]\n",
    "df_top_3_PQ = df_top_3_PQ.groupby(['PROV1_1', 'MAKE_NAME', 'MODEL_NAME'])['Customer_ID'].nunique().reset_index()\\\n",
    ".sort_values(by='Customer_ID', ascending=False)[0:3]\n",
    "df_veh_top_3 = pd.concat([df_top_3_ON, df_top_3_AB, df_top_3_NS, df_top_3_PQ], axis=0)\n",
    "df_veh_top_3 = df_veh_top_3.rename(columns={\"Customer_ID\": \"Customer_ID (Count)\"})\n",
    "print(\"\\nTop 3 most popular vehicles per province:\\n\")\n",
    "print(tabulate(df_veh_top_3, headers='keys'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customers that are TE but NOT if they have both TE and AC policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active = data[data['STATUS_CODE'] == 'AC']\n",
    "df_term = data[data['STATUS_CODE'] == 'TE']\n",
    "\n",
    "df_term = (df_term[~df_term['Customer_ID'].isin(df_active['Customer_ID'])])\n",
    "df_term = df_term['Customer_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customers that are TE but if they have both TE and AC policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_active = data[data['STATUS_CODE'] == 'AC']\n",
    "df_term = data[data['STATUS_CODE'] == 'TE']\n",
    "\n",
    "df_term = (df_term[df_term['Customer_ID'].isin(df_active['Customer_ID'])])\n",
    "df_term = df_term['Customer_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percentage Change from previous row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cum['pct_change'] = (df_cum.groupby('video_id')['count'].apply(pd.Series.pct_change)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bucket column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Column to have buckets (Category datatype)\n",
    "buckets = [0,2500,5000,7500,10000,12500,15000,17500]\n",
    "df_total_views['bucket'] = pd.cut(df_total_views['count'], buckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate function by Customer ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupy(['Customer_ID']).agg({'Calls':'count', 'Claims':{'sum', 'mean'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Join - Customers left and came back (Trans Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby policies and status codes for each customer, then take latest date for each record\n",
    "df_trans_all = df_trans.groupby(['Customer_ID', 'POLICY_NUMBER', 'STATUS_CODE'])['POL_CHGEFF_DATE'].max().reset_index()\n",
    "\n",
    "# Filter new table with only terminated policies for each customer\n",
    "df_trans_term = df_trans_all[(df_trans_all['STATUS_CODE'] == 'TE')]\n",
    "\n",
    "# Merge terminated policies with all policies (Self Join)\n",
    "df_trans_joined = pd.merge(df_trans_term, df_trans_all, on ='Customer_ID', how='left')\n",
    "\n",
    "# Filter date for new policies that occured after original terminated policies for each customer\n",
    "df_trans_joined_filter = df_trans_joined[(df_trans_joined['POL_CHGEFF_DATE_y'] > df_trans_joined['POL_CHGEFF_DATE_x'])]\n",
    "\n",
    "# Filter status for new policies that's active after original terminated policies for each customer\n",
    "df_trans_joined_filter = df_trans_joined_filter[(df_trans_joined_filter['STATUS_CODE_x'] == 'TE')\\\n",
    "                                                & (df_trans_joined_filter['STATUS_CODE_y'] == 'AC')]\n",
    "\n",
    "# Total customers left and came back\n",
    "df_trans_joined_filter['Customer_ID'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When they came back, distribution of customer choosing monoline or multiline (Trans table to Master Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new list of customer id for customer who returned\n",
    "renewed_list = df_trans_joined_filter['Customer_ID'].tolist()\n",
    "\n",
    "# Filter list back to original data (Master table)\n",
    "df_return_id = df_master_age[df_master_age['Customer_ID'].isin(renewed_list)]\n",
    "\n",
    "# Filter for returned customers who has multi products \n",
    "df_auto = df_return_id[df_return_id['LINE_OF_BUSINESS_CODE'] == 'AU']\n",
    "df_prop = df_return_id[df_return_id['LINE_OF_BUSINESS_CODE'] == 'PR']\n",
    "df_multi = (df_auto[df_auto['Customer_ID'].isin(df_prop['Customer_ID'])])\n",
    "multi = df_multi['Customer_ID'].nunique()\n",
    "\n",
    "# Filter for returned customers who has auto only\n",
    "df_only_auto = (df_auto[~df_auto['Customer_ID'].isin(df_prop['Customer_ID'])])\n",
    "df_only_auto = df_only_auto['Customer_ID'].nunique()\n",
    "\n",
    "# Filter for returned customers who has property only\n",
    "df_only_prop = (df_prop[~df_prop['Customer_ID'].isin(df_auto['Customer_ID'])])\n",
    "df_only_prop = df_only_prop['Customer_ID'].nunique()\n",
    "\n",
    "# Total customers left and came back\n",
    "total = df_return_id['Customer_ID'].nunique()\n",
    "total\n",
    "\n",
    "# Distribution of customers that came back have multi products, auto only or property only\n",
    "df_dist = pd.DataFrame({'Multiline for return customer': [round(multi/total*100, 2)],\n",
    "                        'Auto only for reutrn customer': [round(df_only_auto/total*100, 2)],\n",
    "                        'Property only for reutrn customer': [round(df_only_prop/total*100, 2)],})\n",
    "df_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .tail(1) - What was the last product customers dropped (Trans Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filer to lastest transactions for policy\n",
    "df_drop = df_trans.sort_values('POL_CHGEFF_DATE').groupby('POLICY_NUMBER').tail(1)\n",
    "\n",
    "# Filter to terminated status\n",
    "df_drop = df_drop[(df_drop['STATUS_CODE'] == 'TE')]\n",
    "\n",
    "# Distribution of customers who dropped last products\n",
    "df_drop = df_drop.groupby(['LINE_OF_BUSINESS_CODE'])['Customer_ID'].nunique().reset_index()\n",
    "\n",
    "# Total Customers that dropped products\n",
    "total = df_drop['Customer_ID'].sum()\n",
    "\n",
    "# Final distribution with percentage for customers who dropped last products\n",
    "df_drop['Distribution'] = df_drop['Customer_ID'].apply(lambda x: round(x/total*100,2))\n",
    "df_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .tail(2) - Address before and after 1 year change (Trans Table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter date by 1 year\n",
    "date1 = df_trans['POL_CHGEFF_DATE'].max()\n",
    "date2 = df_trans['POL_CHGEFF_DATE'].max() - pd.DateOffset(years=1)\n",
    "df_trans_1year = df_trans[(df_trans['POL_CHGEFF_DATE'] <= date1) & (df_trans['POL_CHGEFF_DATE'] >= date2)]\n",
    "\n",
    "# Filter customers who changed addresses\n",
    "def numChanges(x):\n",
    "    return sum(x.iloc[:-1] != x.shift(-1).iloc[:-1]) # If each row does not equal to each row that's 'SHIFTED' down by 1, return the number of changes\n",
    "df_trans_1year = df_trans_1year.groupby('Customer_ID').agg({'Address_ID':numChanges}).reset_index()\n",
    "df_trans_1year_chg = df_trans_1year[(df_trans_1year['Address_ID'] > 0)]\n",
    "\n",
    "# Create list for customers who changed address\n",
    "new_id = df_trans_1year_chg['Customer_ID'].tolist()\n",
    "df_trans_1year_add = df_trans[df_trans['Customer_ID'].isin(new_id)]\n",
    "df_trans_1year_add = df_trans_1year_add.groupby('Customer_ID').tail(2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# .diff() + .isin() - How often customer churn when they move (Trans Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Includes solving issue with only 1 policy of TE (no previous AC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out terminated policies only\n",
    "df_term = df_trans[df_trans['STATUS_CODE'] == 'TE']\n",
    "\n",
    "# Sort transactions data ascending, by Customer ID, Policy Number and Date\n",
    "df_sort = df_trans.sort_values(by = ['Customer_ID', 'POLICY_NUMBER', 'POL_CHGEFF_DATE'])\n",
    "\n",
    "# Filter out active customers (use sorted table to filter out active customers, show only customer that was AC to TE)\n",
    "df_sort = df_sort[df_sort['Customer_ID'].isin(df_term['Customer_ID'])]\n",
    "total = df_sort['Customer_ID'].nunique()\n",
    "\n",
    "# Filter out SINGLE terminated policies (no previous active policies from historical data)\n",
    "df_issue = df_sort.groupby(['POLICY_NUMBER', 'STATUS_CODE']).size().reset_index()\n",
    "df_issue = df_issue[df_issue[0]==1]\n",
    "df_issue = df_issue[df_issue['STATUS_CODE'] == 'TE']\n",
    "\n",
    "df_sort = df_sort[~df_sort['POLICY_NUMBER'].isin(df_issue['POLICY_NUMBER'])]\n",
    "\n",
    "# Check for address change before customer terminated\n",
    "df_sort['Change'] = df_sort['Address_ID'].diff()\n",
    "\n",
    "# Total number of customers that changed address at termination\n",
    "df_sort = df_sort[df_sort['Change'] != 0.0]\n",
    "df_sort = df_sort['Customer_ID'].nunique()\n",
    "print(df_sort)\n",
    "print(df_sort/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numChange - How often does customer change address in 1 year (Trans Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### numChange function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If each row does not equal to each row that's 'SHIFTED' down by 1, return the number of changes\n",
    "def numChanges(x):\n",
    "    return sum(x.iloc[:-1] != x.shift(-1).iloc[:-1]) \n",
    "df = df.groupby('Customer_ID').agg({'Address_ID':numChanges}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter date by 1 year\n",
    "date1 = df_trans['POL_CHGEFF_DATE'].max()\n",
    "date2 = df_trans['POL_CHGEFF_DATE'].max() - pd.DateOffset(years=1)\n",
    "df_trans_1year = df_trans[(df_trans['POL_CHGEFF_DATE'] <= date1) & (df_trans['POL_CHGEFF_DATE'] >= date2)]\n",
    "\n",
    "# Filter customers who changed addresses\n",
    "def numChanges(x):\n",
    "    return sum(x.iloc[:-1] != x.shift(-1).iloc[:-1]) # If each row does not equal to each row that's 'SHIFTED' down by 1, return the number of changes\n",
    "df_trans_1year = df_trans_1year.groupby('Customer_ID').agg({'Address_ID':numChanges}).reset_index()\n",
    "df_trans_1year_chg = df_trans_1year[(df_trans_1year['Address_ID'] > 0)]\n",
    "\n",
    "# Average number of times customers change address in 1 year\n",
    "print(df_trans_1year['Address_ID'].mean().round(2))\n",
    "print('\\n')\n",
    "\n",
    "# Average number of times customers change address in 1 year (for all customers that moved only)\n",
    "print(df_trans_1year_chg['Address_ID'].mean().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Distribution based on attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of customers in each gender\n",
    "df_gender = df_master_age.groupby(['GENDER_TYPE_CODE'])['Customer_ID'].nunique().reset_index()\n",
    "\n",
    "# Gender composition\n",
    "y = int(df_master_age['Customer_ID'].nunique())\n",
    "df_gender['Composition'] = df_gender['Customer_ID'].apply(lambda x: round((x / y)*100,2))\n",
    "df_gender"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6_1",
   "language": "python",
   "name": "pyfull36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
